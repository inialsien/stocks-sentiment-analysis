{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from senti_classifier import senti_classifier\n",
    "from TwitterAPI import TwitterAPI\n",
    "from datetime import datetime\n",
    "import ConfigParser\n",
    "import pickle\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Established Twitter connection.\n"
     ]
    }
   ],
   "source": [
    "# Connect to the Twitter API and return a TwitterAPI object to use.\n",
    "def get_twitter(config_file):\n",
    "    config = ConfigParser.ConfigParser()\n",
    "    config.read(config_file)\n",
    "    twitter = TwitterAPI(\n",
    "                   config.get('twitter', 'consumer_key'),\n",
    "                   config.get('twitter', 'consumer_secret'),\n",
    "                   config.get('twitter', 'access_token'),\n",
    "                   config.get('twitter', 'access_token_secret'))\n",
    "    return twitter\n",
    "\n",
    "twitter = get_twitter('twitter.cfg')\n",
    "print('Established Twitter connection.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    #Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    #Convert www.* or https?://* to URL\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
    "    #Convert @username to AT_USER\n",
    "    tweet = re.sub('@[^\\s]+','AT_USER',tweet)\n",
    "    #Remove additional white spaces\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    #Replace #word with word\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    #trim\n",
    "    tweet = tweet.strip('\\'\"')\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "\n",
    "def extract_id(tweet_request_response, min_id=998816577052196870):\n",
    "    \"\"\"\n",
    "    Extract the min of tweets' id, use a bad hack to initialize max_id\n",
    "    \"\"\"\n",
    "    for tweet in tweet_request_response:\n",
    "        if tweet['id'] < min_id:\n",
    "            min_id = tweet['id']\n",
    "        \n",
    "    return min_id\n",
    "\n",
    "def gather_tweets(search_query, since, until, tweets_list=[]):\n",
    "    tweets = twitter.request('search/tweets',{'q':search_query, 'lang':'en', 'since':since, 'until':until, 'count':100})\n",
    "    min_id = extract_id(tweets)\n",
    "    \n",
    "    while True:\n",
    "            if not tweets.get_rest_quota():\n",
    "                return tweets_list\n",
    "        \n",
    "            try:\n",
    "                tweets = twitter.request('search/tweets',\n",
    "                             {'q' : search_query, \n",
    "                              'lang' : 'en', \n",
    "                              'since' : since, \n",
    "                              'until' : until,\n",
    "                              'max_id' : min_id-1,\n",
    "                              'count' : 100})\n",
    "            except:\n",
    "                print 'No more quota !'\n",
    "                return tweets_list\n",
    "            \n",
    "            for tweet in tweets:\n",
    "                process_text = process_tweet(tweet['text'])\n",
    "                tweets_list.append({'text': process_text, \n",
    "                                    'author': tweet['user']['name'], \n",
    "                                    'date': datetime.strptime(tweet['created_at'], '%a %b %d %H:%M:%S +0000 %Y').strftime('%Y-%m-%d'),\n",
    "                                    'time': datetime.strptime(tweet['created_at'], '%a %b %d %H:%M:%S +0000 %Y').strftime('%H:%M:%S'),\n",
    "                                   })\n",
    "                \n",
    "            if (extract_id(tweets, min_id=min_id) == min_id):\n",
    "                return tweets_list\n",
    "            else:\n",
    "                min_id = extract_id(tweets, min_id=min_id)\n",
    "            \n",
    "            print 'Next max_id: ' + str(min_id)\n",
    "            print 'Remaining quota: ' + str(tweets.get_rest_quota())\n",
    "    \n",
    "    return tweets_list \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next max_id: 670913730473955328\n",
      "Remaining quota: {'reset': None, 'limit': None, 'remaining': 172}\n",
      "Next max_id: 670772401794252800\n",
      "Remaining quota: {'reset': None, 'limit': None, 'remaining': 171}\n",
      "Next max_id: 670755256553349121\n",
      "Remaining quota: {'reset': None, 'limit': None, 'remaining': 170}\n",
      "Period 2015-11-29 to 2015-11-30 gathered.\n",
      "Period 2015-11-29 to 2015-11-30 written in file.\n"
     ]
    }
   ],
   "source": [
    "period = ['2015-11-29', '2015-11-30']\n",
    "tweets_dico_list = gather_tweets('%24GOOG', period[0], period[1])\n",
    "print 'Period ' + period[0] + ' to ' + period[1] + ' gathered.'\n",
    "pickle.dump(tweets_dico_list, open('save-'+period[0]+'-to-'+period[1]+'.pkl', 'wb' ))\n",
    "print 'Period ' + period[0] + ' to ' + period[1] + ' written in file.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_feeling_avg(tweets_dico_list):\n",
    "    texts_list = []\n",
    "    for tweet in tweets_dico_list:\n",
    "        texts_list.append(tweet['text'])\n",
    "    print 'list finished'\n",
    "    return senti_classifier.polarity_scores(texts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next max_id: 670913730473955328\n",
      "Remaining quota: {'reset': None, 'limit': None, 'remaining': 178}\n",
      "Next max_id: 670772401794252800\n",
      "Remaining quota: {'reset': None, 'limit': None, 'remaining': 177}\n",
      "Next max_id: 670755256553349121\n",
      "Remaining quota: {'reset': None, 'limit': None, 'remaining': 176}\n",
      "list finished\n",
      "(675.75, 418.75)\n"
     ]
    }
   ],
   "source": [
    "print compute_feeling_avg(gather_tweets('%24GOOG', period[0], period[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
