{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from senti_classifier import senti_classifier\n",
    "from TwitterAPI import TwitterAPI\n",
    "from datetime import datetime\n",
    "import ConfigParser\n",
    "import pickle\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Established Twitter connection.\n"
     ]
    }
   ],
   "source": [
    "# Connect to the Twitter API and return a TwitterAPI object to use.\n",
    "def get_twitter(config_file):\n",
    "    config = ConfigParser.ConfigParser()\n",
    "    config.read(config_file)\n",
    "    twitter = TwitterAPI(\n",
    "                   config.get('twitter', 'consumer_key'),\n",
    "                   config.get('twitter', 'consumer_secret'),\n",
    "                   config.get('twitter', 'access_token'),\n",
    "                   config.get('twitter', 'access_token_secret'))\n",
    "    return twitter\n",
    "\n",
    "twitter = get_twitter('twitter.cfg')\n",
    "print('Established Twitter connection.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    #Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    #Convert www.* or https?://* to URL\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
    "    #Convert @username to AT_USER\n",
    "    tweet = re.sub('@[^\\s]+','AT_USER',tweet)\n",
    "    #Remove additional white spaces\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    #Replace #word with word\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    #trim\n",
    "    tweet = tweet.strip('\\'\"')\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "\n",
    "def gather_tweets(search_query, since, until):\n",
    "    tweets = twitter.request('search/tweets',{'q':search_query, 'lang':'en', 'since':since, 'until':until, 'count':1})\n",
    "    print tweets.json()['search_metadata']\n",
    "    max_id = tweets.json()['search_metadata']['since_id_str']\n",
    "\n",
    "    \"\"\"\n",
    "    for i in range(10):\n",
    "            tweets = twitter.request('search/tweets',\n",
    "                             {'q':search_query, \n",
    "                              'lang':'en', \n",
    "                              'since':since, \n",
    "                              'until':until,\n",
    "                              'max_id':max_id,\n",
    "                              'count':100})\n",
    "            \n",
    "            max_id = tweets.json()['search_metadata']['since_id_str']\n",
    "            \n",
    "            for tweet in tweets:\n",
    "                process_text = process_tweet(tweet['text'])\n",
    "                pos_score, neg_score = senti_classifier.polarity_scores(process_text)\n",
    "                dico_tweets.append({'text': process_text, \n",
    "                                    'author': tweet['user']['name'], \n",
    "                                    'date': datetime.strptime(tweet['created_at'], '%a %b %d %H:%M:%S +0000 %Y').strftime('%Y-%m-%d'),\n",
    "                                    'pos_score': pos_score,\n",
    "                                    'neg_score': neg_score\n",
    "                                   })\n",
    "        \n",
    "            print tweets.get_rest_quota()\n",
    "            \n",
    "            if not tweets.get_rest_quota():\n",
    "                return dico_tweets                \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 1, u'completed_in': 0.013, u'max_id_str': u'671115411778379777', u'since_id_str': u'0', u'next_results': u'?max_id=671115411778379776&q=%2524GOOG%20since%3A2015-11-23%20until%3A2015-11-30&lang=en&count=1&include_entities=1', u'refresh_url': u'?since_id=671115411778379777&q=%2524GOOG%20since%3A2015-11-23%20until%3A2015-11-30&lang=en&include_entities=1', u'since_id': 0, u'query': u'%2524GOOG+since%3A2015-11-23+until%3A2015-11-30', u'max_id': 671115411778379777}\n"
     ]
    }
   ],
   "source": [
    "tweets_dic = gather_tweets('%24GOOG', '2015-11-23', '2015-11-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
